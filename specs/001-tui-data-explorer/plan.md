# Implementation Plan: TUI Data Explorer

**Branch**: `001-tui-data-explorer` | **Date**: 2026-01-07 | **Spec**: [spec.md](./spec.md)  
**Input**: Feature specification from `/specs/001-tui-data-explorer/spec.md`

**Note**: This plan is generated by the `/speckit.plan` command following the Phase 0-2 workflow.

## Summary

Build a keyboard-first TUI data exploration tool that allows users to load multiple datasets (local files or remote URLs), perform interactive analysis (filtering, aggregation, pivot tables, joins), and export analyses as executable notebooks. The application must remain responsive with large datasets (1M+ rows, 1GB+ files) using lazy evaluation, support up to 10 simultaneous datasets with independent operation state, and persist analyses to DuckDB for reproducibility.

**Technical Approach**: Use Textual for the reactive TUI framework, narwhals for data source abstraction (supporting pandas/polars/pyarrow backends), Typer for CLI subcommands (`kw load`), DuckDB for analysis persistence, and hybrid async/worker model for non-blocking I/O and CPU-bound operations.

## Technical Context

**Language/Version**: Python >=3.13 (as specified in constitution and pyproject.toml)  
**Primary Dependencies**: 
- textual >=7.0.1 (TUI framework)
- narwhals >=2.15.0 (unified dataframe API)
- typer >=0.9.0 (CLI with subcommands)
- duckdb >=0.10.0 (analysis persistence)
- httpx >=0.27.0 (async HTTP for remote datasets)
- nbformat >=5.10.0 (Jupyter notebook generation)
- jinja2 >=3.1.0 (marimo/Python script templates)

**Storage**: 
- DuckDB file at `~/.kittiwake/analyses.db` (SavedAnalysis entity)
- In-memory dataset state (up to 10 datasets per session)
- Lazy evaluation for large files (delegated to narwhals backends)

**Testing**: 
- pytest >=8.0.0 (unit and integration tests)
- pytest-asyncio (async test support)
- Textual's built-in testing utilities (TUI interaction tests)
- Contract tests for exported notebook/script formats

**Target Platform**: Terminal environments (Linux, macOS, Windows with modern terminal emulators)

**Project Type**: Single Python package with CLI entry point

**Performance Goals**: 
- UI response time: <100ms for keyboard actions (FR-008)
- Progress feedback: operations >500ms show indicators (FR-014, SC-007)
- Dataset switching: <150ms (SC-014)
- Large file loading: 1GB CSV first page within 3 seconds (SC-001)
- 10M+ row responsiveness via lazy evaluation (SC-004)

**Constraints**: 
- Keyboard-only navigation (FR-006, Constitution I)
- No direct pandas/polars API usage, only narwhals (FR-004, Constitution II)
- Async/await for I/O, never block UI >100ms (Constitution IV)
- Max 10 simultaneous datasets (FR-063)
- DuckDB operations <200ms for 1000 analyses (SC-013)

**Scale/Scope**: 
- 7 user stories (P1-P6)
- 62 functional requirements
- 15 success criteria
- Single-user local application (no auth/multi-tenancy)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### I. Keyboard-First Interaction ✅

**Compliance**: 
- FR-006: Keyboard-only navigation for all features
- FR-007: Help overlay with shortcuts
- FR-008: Visual feedback within 100ms
- FR-055: Keyboard shortcuts for dataset switching
- All user stories describe keyboard-driven workflows

**No violations.**

### II. Data Source Agnostic ✅

**Compliance**:
- FR-001/002: Local files and remote URLs
- FR-004: narwhals unified API mandatory, no direct pandas/polars
- FR-005: Lazy evaluation for large files (narwhals backend support)
- Spec explicitly mentions "no direct pandas/polars usage"

**No violations.**

### III. TUI-Native Design ✅

**Compliance**:
- Constitution mandates Textual framework primitives
- FR-009: Layout adapts to terminal resize (Textual reactive model)
- FR-010: Light/dark theme support (Textual built-in)
- Plan uses Textual widgets (DataTable, TabbedContent, Footer, etc.)

**No violations.**

### IV. Performance & Responsivity ✅

**Compliance**:
- FR-008: 100ms UI response threshold
- FR-014: Progress indicators for >500ms operations
- FR-015: Cancellable long-running operations
- SC-001-004: Performance targets with large datasets
- Async/worker hybrid model for non-blocking I/O and CPU operations

**No violations.**

### V. Composable Operations ✅

**Compliance**:
- FR-033-036: Save operation sequences as workflows
- FR-036: Undo/redo for operations
- FR-031: Preview before applying (merge operations)
- User Story 3/4/5/6: Chaining filter → group → aggregate → pivot
- Each dataset maintains independent operation history (FR-059)

**No violations.**

### Technology Stack ✅

**Compliance**:
- Python >=3.13 ✅ (pyproject.toml)
- uv as package manager ✅ (constitution requirement)
- narwhals >=2.15.0 ✅ (pyproject.toml)
- textual >=7.0.1 ✅ (pyproject.toml)
- marimo >=0.18.4 ✅ (dev dependencies in pyproject.toml)

**No violations.**

### Documentation Standards ✅

**Compliance**:
- FR-046: Export to marimo notebooks
- Constitution requires marimo for interactive examples
- Plan includes marimo notebook templates in Phase 1
- Future docs will include `docs/examples/` with marimo notebooks

**No violations. Note**: Documentation creation is out of scope for this feature implementation but export capability enables it.

---

**GATE STATUS**: ✅ **PASSED** - All constitution principles satisfied. Proceed to Phase 0.

## Project Structure

### Documentation (this feature)

```text
specs/001-tui-data-explorer/
├── spec.md              # Feature specification (already exists)
├── plan.md              # This file (created by /speckit.plan)
├── research.md          # Phase 0 output (to be generated)
├── data-model.md        # Phase 1 output (to be generated)
├── quickstart.md        # Phase 1 output (to be generated)
├── contracts/           # Phase 1 output (to be generated)
│   ├── cli-interface.md
│   ├── saved-analysis-schema.sql
│   ├── export-marimo.jinja2
│   ├── export-python.jinja2
│   └── export-jupyter.json
└── tasks.md             # Phase 2 output (created by /speckit.tasks - NOT by /speckit.plan)
```

### Source Code (repository root)

```text
# Single project structure (constitution compliant)
src/kittiwake/
├── __init__.py          # Entry point with main() function
├── cli.py               # Typer CLI app with subcommands (kw, kw load)
├── app.py               # Main Textual App class
├── models/
│   ├── __init__.py
│   ├── dataset.py       # Dataset, DatasetSession entities
│   ├── operations.py    # Filter, Aggregation, PivotTable, Workflow
│   └── saved_analysis.py # SavedAnalysis entity + DuckDB persistence
├── widgets/
│   ├── __init__.py
│   ├── dataset_table.py # Main data display widget (Textual DataTable)
│   ├── dataset_tabs.py  # Tab bar for loaded datasets
│   ├── filter_modal.py  # Filter input modal
│   ├── aggregation_panel.py # Aggregation results display
│   └── help_overlay.py  # Keyboard shortcuts help
├── screens/
│   ├── __init__.py
│   ├── main_screen.py   # Primary data exploration screen
│   ├── merge_screen.py  # Join/merge wizard screen
│   └── saved_analyses_screen.py # Browse/manage saved analyses
├── services/
│   ├── __init__.py
│   ├── data_loader.py   # Load datasets from files/URLs (async)
│   ├── narwhals_ops.py  # Wrapper for narwhals operations (workers)
│   ├── export_service.py # Generate marimo/Python/Jupyter exports
│   └── persistence.py   # DuckDB CRUD operations for SavedAnalysis
└── utils/
    ├── __init__.py
    ├── async_helpers.py # Async/worker utilities
    └── keybindings.py   # Centralized keyboard shortcut definitions

tests/
├── contract/
│   ├── test_cli_contract.py        # CLI interface stability tests
│   ├── test_saved_analysis_schema.py # DuckDB schema validation
│   └── test_export_formats.py      # Verify exported notebooks execute
├── integration/
│   ├── test_dataset_loading.py     # Load CSV/Parquet/JSON/URL
│   ├── test_multi_dataset.py       # 10 dataset limit, switching
│   ├── test_operations_chain.py    # Filter → aggregate → pivot workflow
│   └── test_export_roundtrip.py    # Save → export → execute
└── unit/
    ├── test_models.py               # Entity classes
    ├── test_narwhals_ops.py         # Operation wrappers
    ├── test_persistence.py          # DuckDB CRUD
    └── test_export_templates.py     # Template rendering

docs/ (future, out of scope for this feature)
├── guides/
├── examples/          # marimo notebooks demonstrating features
└── api/

pyproject.toml         # Dependencies defined (already exists)
README.md              # Quick start guide
```

**Structure Decision**: Single project structure selected per constitution default. The `src/kittiwake/` layout follows standard Python packaging with clear separation:
- `models/` - Domain entities (Dataset, Filter, SavedAnalysis, etc.)
- `widgets/` - Reusable Textual UI components
- `screens/` - Full-screen Textual layouts
- `services/` - Business logic layer (data loading, operations, persistence, export)
- `utils/` - Cross-cutting helpers

This structure supports:
- Constitution-mandated keyboard-first design (centralized keybindings)
- TUI-native architecture (screens/widgets separate from business logic)
- Composable operations (services layer orchestrates narwhals operations)
- Testing at all layers (contract/integration/unit separation)

## Complexity Tracking

**No constitutional violations to justify.** All gates passed.

---

## Phase 0: Research & Technical Decisions

### Research Tasks

The following unknowns from Technical Context must be resolved before Phase 1 design:

1. **Textual DataTable Performance with Large Datasets**
   - Question: Can Textual's DataTable handle 1M+ rows with lazy loading/pagination?
   - Research: Textual DataTable virtual scrolling capabilities, pagination patterns
   - Acceptance: Identify max rows per page, scrolling strategy, memory constraints

2. **Narwhals Backend Detection & Lazy Evaluation**
   - Question: How to detect available backends (pandas/polars) and configure lazy mode?
   - Research: narwhals backend selection API, lazy frame support per backend
   - Acceptance: Code pattern for backend-agnostic lazy loading

3. **Async HTTP with Narwhals**
   - Question: Best pattern for downloading remote datasets without blocking UI?
   - Research: httpx streaming, temp file handling, progress tracking
   - Acceptance: Async data loader that streams to disk, then loads with narwhals

4. **Textual Workers for CPU-Bound Operations**
   - Question: How to run narwhals operations (filter, aggregate) in workers without blocking UI?
   - Research: Textual worker API, data serialization, cancellation
   - Acceptance: Worker pattern for filter/aggregate with progress updates

5. **DuckDB Concurrency Model**
   - Question: Can multiple sessions safely read/write `~/.kittiwake/analyses.db`?
   - Research: DuckDB locking, WAL mode, concurrent access patterns
   - Acceptance: Safe CRUD pattern for SavedAnalysis persistence

6. **Keyboard Shortcut Management**
   - Question: How to implement context-aware shortcuts (different keys per screen)?
   - Research: Textual bindings system, action routing, help overlay patterns
   - Acceptance: Centralized binding definition with per-screen overrides

7. **Undo/Redo Implementation**
   - Question: Best pattern for operation history with narwhals (immutable operations)?
   - Research: Command pattern, memento pattern, narwhals query serialization
   - Acceptance: Undo/redo design that doesn't recompute full dataset chain

8. **Export Template Requirements**
   - Question: What imports/setup code must be in marimo vs Python vs Jupyter exports?
   - Research: marimo cell structure, Jupyter kernel requirements, narwhals import patterns
   - Acceptance: Template structure for each format with example output

### Research Deliverable

Create `research.md` with sections:

```markdown
# Research Findings: TUI Data Explorer

## 1. Textual DataTable Performance
- **Decision**: [pagination strategy]
- **Rationale**: [why chosen]
- **Alternatives considered**: [what else evaluated]

## 2. Narwhals Backend Detection
[...]

[... 8 sections total ...]

## Summary of Technical Decisions
[Consolidated table of all decisions]
```

**Output**: `specs/001-tui-data-explorer/research.md`

---

## Phase 1: Design & Contracts

**Prerequisites**: `research.md` complete with all decisions finalized.

### 1.1 Data Model Design

Extract entities from spec and design concrete implementations:

**File**: `specs/001-tui-data-explorer/data-model.md`

**Content Structure**:
```markdown
# Data Model: TUI Data Explorer

## Core Entities

### Dataset
**Purpose**: Represents a loaded dataset in the session.

**Fields**:
- id: UUID (unique session identifier)
- name: str (display name, derived from file path)
- source: str (file path or URL)
- backend: str (pandas/polars/pyarrow - detected by narwhals)
- frame: narwhals.DataFrame | narwhals.LazyFrame
- schema: dict[str, str] (column_name → dtype)
- row_count: int (total rows)
- is_active: bool (currently displayed in main view)
- operation_history: list[Operation] (applied filters/aggregations)

**Relationships**:
- Contained in DatasetSession (1:N)
- References Operations (1:N)

**Validation Rules**:
- name must be unique within session
- source must be valid file path or HTTP(S) URL
- frame must use narwhals API (no direct pandas/polars)

**State Transitions**:
- LOADING → READY → ACTIVE/INACTIVE → CLOSED

[... continue for all entities: DatasetSession, Filter, Aggregation, PivotTable, Workflow, SavedAnalysis ...]

## Persistence Schema (DuckDB)

### SavedAnalysis Table
```sql
CREATE TABLE saved_analyses (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    description TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    modified_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    operation_count INTEGER NOT NULL,
    dataset_path TEXT NOT NULL,
    operations JSON NOT NULL
);

CREATE INDEX idx_name ON saved_analyses(name);
CREATE INDEX idx_created_at ON saved_analyses(created_at DESC);
```

[... DuckDB schema details ...]

## Operation Serialization

[JSON schema for Filter, Aggregation, PivotTable operations - needed for SavedAnalysis.operations field and export templates]
```

### 1.2 API Contracts

**Directory**: `specs/001-tui-data-explorer/contracts/`

**Files to Generate**:

1. **`cli-interface.md`** - CLI contract (semver stability)
```markdown
# CLI Interface Contract

## Commands

### `kw`
Launches TUI with empty workspace.

**Exit Codes**:
- 0: Normal exit
- 1: Error (file not found, invalid config, etc.)

### `kw load <paths...>`
Launches TUI and loads datasets.

**Arguments**:
- `<paths...>`: 1+ file paths or URLs (positional, required)

**Behavior**:
- Loads up to 10 datasets
- First dataset becomes active
- Displays warning if >10 provided
- Continues if some files fail to load

**Examples**:
```bash
kw load data.csv
kw load sales.parquet customers.csv https://example.com/data.json
```

[... complete CLI documentation ...]
```

2. **`saved-analysis-schema.sql`** - DuckDB schema (versioned)
```sql
-- SavedAnalysis Schema Version 1.0
-- Compatible with: kittiwake >=0.1.0

CREATE TABLE IF NOT EXISTS saved_analyses (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    description TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    modified_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    operation_count INTEGER NOT NULL,
    dataset_path TEXT NOT NULL,
    operations JSON NOT NULL  -- See operations-schema.json
);

-- Indices for performance (SC-013: <200ms for 1000 analyses)
CREATE INDEX IF NOT EXISTS idx_name ON saved_analyses(name);
CREATE INDEX IF NOT EXISTS idx_created_at ON saved_analyses(created_at DESC);
```

3. **`operations-schema.json`** - JSON schema for operation serialization
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "Kittiwake Operations",
  "type": "array",
  "items": {
    "oneOf": [
      {
        "type": "object",
        "properties": {
          "type": {"const": "filter"},
          "column": {"type": "string"},
          "operator": {"enum": ["=", "!=", ">", "<", ">=", "<=", "contains"]},
          "value": {"type": ["string", "number", "boolean"]}
        },
        "required": ["type", "column", "operator", "value"]
      },
      {
        "type": "object",
        "properties": {
          "type": {"const": "aggregate"},
          "column": {"type": "string"},
          "functions": {"type": "array", "items": {"enum": ["count", "sum", "mean", "median", "min", "max", "std"]}},
          "group_by": {"type": "array", "items": {"type": "string"}}
        },
        "required": ["type", "column", "functions"]
      }
    ]
  }
}
```

4. **`export-marimo.jinja2`** - marimo notebook template
```python
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "narwhals>=2.15.0",
#     "marimo",
# ]
# ///

import marimo

__generated_with__ = "{{ app_version }}"
_mo = marimo

# %% [markdown]
"""
# {{ analysis_name }}

{{ analysis_description }}

**Generated**: {{ generated_at }}  
**Source Dataset**: {{ dataset_path }}  
**Operations**: {{ operation_count }}
"""

# %% [python]
import narwhals as nw

# Load dataset
df = nw.from_native(nw.read_csv("{{ dataset_path }}"))

# %% [python]
{% for operation in operations %}
# Operation {{ loop.index }}: {{ operation.type }}
{% if operation.type == "filter" %}
df = df.filter(nw.col("{{ operation.column }}") {{ operation.operator }} {{ operation.value | repr }})
{% elif operation.type == "aggregate" %}
df = df.group_by({{ operation.group_by | repr }}).agg([
    {% for func in operation.functions %}
    nw.col("{{ operation.column }}").{{ func }}().alias("{{ operation.column }}_{{ func }}"){{ "," if not loop.last }}
    {% endfor %}
])
{% endif %}

{% endfor %}

# %% [python]
# Display results
_mo.ui.table(df.to_pandas())
```

5. **`export-python.jinja2`** - Python script template
6. **`export-jupyter.json`** - Jupyter notebook structure (nbformat)

### 1.3 Quickstart Guide

**File**: `specs/001-tui-data-explorer/quickstart.md`

```markdown
# Quickstart: TUI Data Explorer Development

## Prerequisites

- Python >=3.13
- uv package manager

## Setup

```bash
# Clone and install
git clone <repo>
cd kittiwake
uv sync

# Run tests
uv run pytest

# Launch TUI
uv run kw
```

## Development Workflow

### Adding a New Widget

1. Create `src/kittiwake/widgets/my_widget.py`
2. Extend `textual.widgets.Widget`
3. Add to `src/kittiwake/screens/main_screen.py`
4. Write unit test in `tests/unit/test_widgets.py`

[... examples for common tasks ...]

## Key Architecture Patterns

### Loading Data (Async)
```python
from kittiwake.services.data_loader import DataLoader

async def load_dataset(path: str):
    loader = DataLoader()
    dataset = await loader.load(path)  # Non-blocking
    return dataset
```

### Running Operations (Workers)
```python
from textual.worker import work

@work(exclusive=True)
async def apply_filter(dataset, filter_spec):
    # Runs in worker, doesn't block UI
    result = await run_in_executor(narwhals_ops.filter, dataset, filter_spec)
    return result
```

[... more patterns ...]
```

### 1.4 Agent Context Update

Run the agent context update script:

```bash
cd /Users/larky/Code/kittiwake
.specify/scripts/bash/update-agent-context.sh opencode
```

This will update `.claude/` context files with technology stack from this plan:
- textual >=7.0.1
- narwhals >=2.15.0
- typer >=0.9.0
- duckdb >=0.10.0
- httpx >=0.27.0
- nbformat >=5.10.0
- jinja2 >=3.1.0

**Manual additions** (outside agent markers) will be preserved.

---

## Post-Phase 1 Constitution Re-Check

*Run after data-model.md and contracts/ are complete.*

**Check**: Do the concrete designs still satisfy all constitutional principles?

- ✅ Keyboard-First: Verify keybindings.py covers all operations
- ✅ Data Source Agnostic: Verify narwhals_ops.py uses only narwhals API
- ✅ TUI-Native: Verify widgets/ only use Textual primitives
- ✅ Performance: Verify async/worker patterns in services/
- ✅ Composable: Verify operation serialization in operations-schema.json

**If any violations found**: Document in Complexity Tracking and justify or redesign.

---

## Next Steps

1. **Execute Phase 0**: Generate `research.md` by dispatching research tasks
2. **Execute Phase 1**: Generate `data-model.md`, `contracts/`, `quickstart.md`
3. **Update agent context**: Run update script
4. **Re-check constitution**: Verify Phase 1 artifacts satisfy principles
5. **Stop here**: This command (`/speckit.plan`) ends after Phase 1

**To continue to task breakdown**: Run `/speckit.tasks` (separate command)

---

**Plan Status**: ✅ Ready for Phase 0 execution  
**Branch**: `001-tui-data-explorer`  
**Next Command**: Agent will now execute Phase 0 research

---

## Phase 1.5: Modal Specifications (NEW - Added 2026-01-08)

**Context**: Operations are now stored as narwhals code strings generated by keyboard-driven modal forms. This phase defines modal UX patterns and code generation logic.

### Modal Design Principles

1. **Keyboard-First**: All modals navigate via keyboard (Tab, Arrow keys, Enter, Esc)
2. **Immediate Validation**: Validate inputs on modal submit using sample data
3. **Code Preview**: Show generated narwhals code before applying (optional toggle)
4. **Edit Capability**: Pre-fill modal fields when editing existing operations from params

### Modal Specifications (13 Types)

#### 1. Filter Modal

**Trigger**: `f` key on main data view

**Fields**:
- Column (dropdown): Select from dataset schema columns
- Operator (dropdown): `=`, `!=`, `>`, `<`, `>=`, `<=`, `contains`, `startswith`, `endswith`, `isnull`, `notnull`
- Value (input): Text/number input (disabled for `isnull`/`notnull`)

**Code Generation**:
```python
# Example: column="age", operator=">", value=25
"df.filter(nw.col('age') > 25)"
```

**Validation**: Check column exists, value type matches column dtype

**Display Generation**: `"Filter: {column} {operator} {value}"`

---

#### 2. Aggregate Modal

**Trigger**: `a` key on main data view

**Fields**:
- Column (dropdown): Target column to aggregate
- Functions (multi-select checklist): count, sum, mean, median, min, max, std, var, nunique
- Group By (multi-select): Optional grouping columns

**Code Generation**:
```python
# Example: column="sales", functions=["sum", "mean"], group_by=["region"]
"df.group_by('region').agg([nw.col('sales').sum().alias('sales_sum'), nw.col('sales').mean().alias('sales_mean')])"
```

**Validation**: Check numeric column for sum/mean/std, group_by columns exist

**Display Generation**: `"Aggregate: {FUNCTIONS} of {column}[ grouped by {group_by}]"`

---

#### 3. Sort Modal

**Trigger**: `s` key on main data view

**Fields**:
- Columns (multi-select ordered list): Columns to sort by (with reorder capability)
- Descending (checkbox per column): Sort direction for each column

**Code Generation**:
```python
# Example: columns=["date", "price"], descending=[True, False]
"df.sort(['date', 'price'], descending=[True, False])"
```

**Display Generation**: `"Sort: {col1} (desc/asc), {col2} (desc/asc)"`

---

#### 4. Select Columns Modal

**Trigger**: `c` key on main data view

**Fields**:
- Columns (multi-select checklist): Columns to keep

**Code Generation**:
```python
# Example: columns=["name", "email", "age"]
"df.select(['name', 'email', 'age'])"
```

**Display Generation**: `"Select: {comma-separated columns}"`

---

#### 5. Drop Columns Modal

**Trigger**: `d` + `c` key sequence

**Fields**:
- Columns (multi-select checklist): Columns to remove

**Code Generation**:
```python
"df.drop(['col1', 'col2'])"
```

**Display Generation**: `"Drop: {comma-separated columns}"`

---

#### 6. Rename Columns Modal

**Trigger**: `r` key

**Fields**:
- Mapping (key-value pairs): Old name → New name (dynamic add/remove rows)

**Code Generation**:
```python
# Example: {old1: new1, old2: new2}
"df.rename({'old1': 'new1', 'old2': 'new2'})"
```

**Display Generation**: `"Rename: {count} columns"`

---

#### 7. Calculated Column Modal

**Trigger**: `w` key (with_columns)

**Fields**:
- New Column Name (text input)
- Expression Builder:
  - Column selector (dropdown)
  - Operator buttons (+, -, *, /, etc.)
  - Value input
  - Expression preview (shows current expression)

**Code Generation**:
```python
# Example: new_column="total", expression="price * quantity"
"df.with_columns((nw.col('price') * nw.col('quantity')).alias('total'))"
```

**Validation**: Parse expression, check column references exist

**Display Generation**: `"Add column: {new_column} = {expression}"`

---

#### 8. Join Modal

**Trigger**: `j` key

**Fields**:
- Right Dataset (dropdown): Select from loaded datasets
- Left On (dropdown): Column from current dataset
- Right On (dropdown): Column from right dataset
- Join Type (radio buttons): inner, left, right, outer, cross

**Code Generation**:
```python
# Example: right="dataset2", left_on="id", right_on="user_id", how="inner"
"df.join(dataset2_df, left_on='id', right_on='user_id', how='inner')"
```

**Validation**: Check columns exist in respective datasets, warn on type mismatches

**Display Generation**: `"Join ({how}): {right_dataset} on {left_on}={right_on}"`

---

#### 9. Pivot Modal

**Trigger**: `p` key

**Fields**:
- Row Dimensions (multi-select): Columns for row groupings
- Column Dimensions (multi-select): Columns for column headers
- Values (list of column + function pairs): Aggregations to compute

**Code Generation**:
```python
# Complex - may use group_by + reshape depending on narwhals pivot support
# Placeholder implementation using group_by
"df.group_by(['row_dim', 'col_dim']).agg([nw.col('value_col').sum().alias('sum')])"
```

**Display Generation**: `"Pivot: {row_dims} × {col_dims} → {value_specs}"`

---

#### 10. Drop Duplicates Modal

**Trigger**: `u` key (unique)

**Fields**:
- Subset Columns (multi-select, optional): Check duplicates only on these columns
- Keep (radio): first, last, none

**Code Generation**:
```python
# Example: subset=["email"], keep="first"
"df.unique(subset=['email'], keep='first')"
```

**Display Generation**: `"Drop duplicates[ on {subset}] (keep {keep})"`

---

#### 11. Fill Null Modal

**Trigger**: `n` + `f` key sequence

**Fields**:
- Strategy (dropdown): forward, backward, mean, median, zero, literal
- Value (input, shown if strategy=literal): Fill value

**Code Generation**:
```python
# Example: strategy="mean"
"df.fill_null(strategy='mean')"

# Example: strategy="literal", value=0
"df.fill_null(0)"
```

**Display Generation**: `"Fill nulls: {strategy}[ with {value}]"`

---

#### 12. Drop Nulls Modal

**Trigger**: `n` + `d` key sequence

**Fields**:
- Subset Columns (multi-select, optional): Drop rows with nulls only in these columns

**Code Generation**:
```python
# Example: subset=["email", "phone"]
"df.drop_nulls(subset=['email', 'phone'])"

# No subset
"df.drop_nulls()"
```

**Display Generation**: `"Drop rows with nulls[ in {subset}]"`

---

#### 13. Sample Modal

**Trigger**: `h` (head), `t` (tail), `m` (sample) keys

**Fields**:
- N (number input): Number of rows
- Random (checkbox, sample only): Use random sampling
- Seed (number input, sample only): Random seed for reproducibility

**Code Generation**:
```python
# Head
"df.head(100)"

# Tail
"df.tail(50)"

# Sample
"df.sample(n=1000, seed=42)"
```

**Display Generation**: `"{operation}: {n} rows[ (random, seed={seed})]"`

---

### Code Generation Architecture

**CodeGenerator Class**:
```python
class CodeGenerator:
    """Generates narwhals code from modal parameters."""
    
    @staticmethod
    def generate_filter(params: dict) -> str:
        """Generate filter code from params."""
        # Logic to build df.filter(...) string
    
    @staticmethod
    def generate_aggregate(params: dict) -> str:
        """Generate aggregate code from params."""
        # Logic to build df.group_by().agg(...) string
    
    # ... 11 more generator methods
    
    @classmethod
    def generate(cls, operation_type: str, params: dict) -> str:
        """Route to appropriate generator based on type."""
        generator_map = {
            "filter": cls.generate_filter,
            "aggregate": cls.generate_aggregate,
            # ... others
        }
        return generator_map[operation_type](params)
```

**DisplayGenerator Class**:
```python
class DisplayGenerator:
    """Generates human-readable descriptions from params."""
    
    @staticmethod
    def format_filter(params: dict) -> str:
        """Format filter display string."""
        col, op, val = params["column"], params["operator"], params.get("value")
        if op in ["isnull", "notnull"]:
            return f"Filter: {col} {op}"
        return f"Filter: {col} {op} {val!r}"
    
    # ... 12 more formatters
```

---

### Validation Strategy

**Two-Phase Validation**:

1. **Modal Submit Validation** (immediate):
   ```python
   def validate_on_submit(operation_code: str, dataset: Dataset) -> tuple[bool, str | None]:
       """Validate code against sample data."""
       try:
           sample = dataset.get_page(0, 10)  # First 10 rows
           exec_namespace = {"df": sample.lazy(), "nw": nw}
           result = eval(operation_code, {"__builtins__": {}}, exec_namespace)
           result.collect()  # Force execution
           return (True, None)
       except Exception as e:
           return (False, f"Validation failed: {str(e)}")
   ```

2. **Runtime Validation** (when applying to full dataset):
   - Same logic but on full dataset
   - If fails, stop operation chain and show error modal
   - User can choose to: edit operation, remove operation, or cancel

---

### Next Steps

1. Implement modal widgets using Textual Screen/Container/Input components
2. Build CodeGenerator + DisplayGenerator classes
3. Wire modal triggers to keyboard bindings in MainScreen
4. Implement validation logic in Dataset.apply_operation()
5. Add operation editing capability (load params → pre-fill modal)

